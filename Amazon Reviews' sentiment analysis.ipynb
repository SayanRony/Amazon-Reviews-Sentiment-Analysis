## **Amazon Sentiment Analysis using Logistic Regression and SVM** 

### **About the dataset:**

The Amazon reviews full score dataset is constructed by randomly taking 600,000 training samples and 130,000 testing samples for each review score from 1 to 5. In total there are 3,000,000 trainig samples and 650,000 testing samples.

The files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3 columns in them, corresponding to class index (1 to 5), review title and review text. The review title and text are escaped using double quotes ("), and any internal double quote is escaped by 2 double quotes (""). New lines are escaped by a backslash followed with an "n" character, that is "\n".

Dataset link: https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M?resourcekey=0-TLwzfR2O-D2aPitmn5o9VQ

Kaggle link: https://www.kaggle.com/datasets/bittlingmayer/amazonreviews/data


```python
import re
import nltk
import pickle
import pandas as pd
import numpy as np
import requests
import joblib
```


```python
# Data processing
from nltk import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer
```


```python
# Feature extraction
!pip install yellowbrick
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer
from yellowbrick.text import FreqDistVisualizer
```

    Defaulting to user installation because normal site-packages is not writeable
    Requirement already satisfied: yellowbrick in c:\users\srinj\appdata\roaming\python\python312\site-packages (1.5)
    Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in c:\programdata\anaconda3\lib\site-packages (from yellowbrick) (3.9.2)
    Requirement already satisfied: scipy>=1.0.0 in c:\programdata\anaconda3\lib\site-packages (from yellowbrick) (1.13.1)
    Requirement already satisfied: scikit-learn>=1.0.0 in c:\programdata\anaconda3\lib\site-packages (from yellowbrick) (1.5.1)
    Requirement already satisfied: numpy>=1.16.0 in c:\programdata\anaconda3\lib\site-packages (from yellowbrick) (1.26.4)
    Requirement already satisfied: cycler>=0.10.0 in c:\programdata\anaconda3\lib\site-packages (from yellowbrick) (0.11.0)
    Requirement already satisfied: contourpy>=1.0.1 in c:\programdata\anaconda3\lib\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.2.0)
    Requirement already satisfied: fonttools>=4.22.0 in c:\programdata\anaconda3\lib\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.51.0)
    Requirement already satisfied: kiwisolver>=1.3.1 in c:\programdata\anaconda3\lib\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.4)
    Requirement already satisfied: packaging>=20.0 in c:\programdata\anaconda3\lib\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (24.1)
    Requirement already satisfied: pillow>=8 in c:\programdata\anaconda3\lib\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (10.4.0)
    Requirement already satisfied: pyparsing>=2.3.1 in c:\programdata\anaconda3\lib\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.1.2)
    Requirement already satisfied: python-dateutil>=2.7 in c:\programdata\anaconda3\lib\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.9.0.post0)
    Requirement already satisfied: joblib>=1.2.0 in c:\programdata\anaconda3\lib\site-packages (from scikit-learn>=1.0.0->yellowbrick) (1.4.2)
    Requirement already satisfied: threadpoolctl>=3.1.0 in c:\programdata\anaconda3\lib\site-packages (from scikit-learn>=1.0.0->yellowbrick) (3.5.0)
    Requirement already satisfied: six>=1.5 in c:\programdata\anaconda3\lib\site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.16.0)
    


```python
# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn import set_config
```


```python
# Evaluation
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
```


```python
# Data Visualization
!pip install wordcloud
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.style as style
from PIL import Image
from wordcloud import WordCloud,  ImageColorGenerator
```

    Defaulting to user installation because normal site-packages is not writeable
    Requirement already satisfied: wordcloud in c:\users\srinj\appdata\roaming\python\python312\site-packages (1.9.4)
    Requirement already satisfied: numpy>=1.6.1 in c:\programdata\anaconda3\lib\site-packages (from wordcloud) (1.26.4)
    Requirement already satisfied: pillow in c:\programdata\anaconda3\lib\site-packages (from wordcloud) (10.4.0)
    Requirement already satisfied: matplotlib in c:\programdata\anaconda3\lib\site-packages (from wordcloud) (3.9.2)
    Requirement already satisfied: contourpy>=1.0.1 in c:\programdata\anaconda3\lib\site-packages (from matplotlib->wordcloud) (1.2.0)
    Requirement already satisfied: cycler>=0.10 in c:\programdata\anaconda3\lib\site-packages (from matplotlib->wordcloud) (0.11.0)
    Requirement already satisfied: fonttools>=4.22.0 in c:\programdata\anaconda3\lib\site-packages (from matplotlib->wordcloud) (4.51.0)
    Requirement already satisfied: kiwisolver>=1.3.1 in c:\programdata\anaconda3\lib\site-packages (from matplotlib->wordcloud) (1.4.4)
    Requirement already satisfied: packaging>=20.0 in c:\programdata\anaconda3\lib\site-packages (from matplotlib->wordcloud) (24.1)
    Requirement already satisfied: pyparsing>=2.3.1 in c:\programdata\anaconda3\lib\site-packages (from matplotlib->wordcloud) (3.1.2)
    Requirement already satisfied: python-dateutil>=2.7 in c:\programdata\anaconda3\lib\site-packages (from matplotlib->wordcloud) (2.9.0.post0)
    Requirement already satisfied: six>=1.5 in c:\programdata\anaconda3\lib\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)
    


```python
style.use("fivethirtyeight")
colors = ["#8ecae6", "#219ebc", "#023047", "#ffb703", "#fb8500"]
palette = sns.color_palette(colors)
sns.palplot(sns.color_palette(colors))
plt.show()
style.use("fivethirtyeight")
```


    
![png](output_9_0.png)
    


#### **Importing the Dataset:**


```python
data = pd.read_csv('./train.csv', header=None)
data.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>more like funchuck</td>
      <td>Gave this to my dad for a gag gift after direc...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>Inspiring</td>
      <td>I hope a lot of people hear this cd. We need m...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>The best soundtrack ever to anything.</td>
      <td>I'm reading a lot of reviews saying that this ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Chrono Cross OST</td>
      <td>The music of Yasunori Misuda is without questi...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Too good to be true</td>
      <td>Probably the greatest soundtrack in history! U...</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>There's a reason for the price</td>
      <td>There's a reason this CD is so expensive, even...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>Buyer beware</td>
      <td>This is a self-published book, and if you want...</td>
    </tr>
    <tr>
      <th>7</th>
      <td>4</td>
      <td>Errors, but great story</td>
      <td>I was a dissapointed to see errors on the back...</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1</td>
      <td>The Worst!</td>
      <td>A complete waste of time. Typographical errors...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1</td>
      <td>Oh please</td>
      <td>I guess you have to be a romance novel lover f...</td>
    </tr>
  </tbody>
</table>
</div>




```python
data.shape
```




    (3000000, 3)



#### **Modifying the Dataset:**

We first name the columns as "Rating", "Title" and "Review".


```python
data.columns = ["Rating", "Title", "Review"]
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Rating</th>
      <th>Title</th>
      <th>Review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>more like funchuck</td>
      <td>Gave this to my dad for a gag gift after direc...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>Inspiring</td>
      <td>I hope a lot of people hear this cd. We need m...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>The best soundtrack ever to anything.</td>
      <td>I'm reading a lot of reviews saying that this ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Chrono Cross OST</td>
      <td>The music of Yasunori Misuda is without questi...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Too good to be true</td>
      <td>Probably the greatest soundtrack in history! U...</td>
    </tr>
  </tbody>
</table>
</div>



We then combine the "Review" and "Title" column into one, as it should not contradict the overall sentiment.


```python
data["Review"] = data["Title"] + " " + data["Review"]
data = data[['Review', 'Rating']]
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Review</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>more like funchuck Gave this to my dad for a g...</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Inspiring I hope a lot of people hear this cd....</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The best soundtrack ever to anything. I'm read...</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Chrono Cross OST The music of Yasunori Misuda ...</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Too good to be true Probably the greatest soun...</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>



The sentiment to each review is added by considering a rating above 3 as "Positive", below 3 as "Negative" and equal to 3 as "Neutral".


```python
def sentiment(label):
    if label<3:
        return "Negative"
    elif label>3:
        return "Positive"
    else:
        return "Neutral"
```


```python
data['Sentiment'] = data["Rating"].apply(sentiment)
data.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Review</th>
      <th>Rating</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>more like funchuck Gave this to my dad for a g...</td>
      <td>3</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Inspiring I hope a lot of people hear this cd....</td>
      <td>5</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The best soundtrack ever to anything. I'm read...</td>
      <td>5</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Chrono Cross OST The music of Yasunori Misuda ...</td>
      <td>4</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Too good to be true Probably the greatest soun...</td>
      <td>5</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>5</th>
      <td>There's a reason for the price There's a reaso...</td>
      <td>5</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Buyer beware This is a self-published book, an...</td>
      <td>1</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Errors, but great story I was a dissapointed t...</td>
      <td>4</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>8</th>
      <td>The Worst! A complete waste of time. Typograph...</td>
      <td>1</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Oh please I guess you have to be a romance nov...</td>
      <td>1</td>
      <td>Negative</td>
    </tr>
  </tbody>
</table>
</div>



#### **Data Analysis:**


```python
data.shape
```




    (3000000, 3)




```python
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 3000000 entries, 0 to 2999999
    Data columns (total 3 columns):
     #   Column     Dtype 
    ---  ------     ----- 
     0   Review     object
     1   Rating     int64 
     2   Sentiment  object
    dtypes: int64(1), object(2)
    memory usage: 68.7+ MB
    


```python
data.value_counts("Rating")
```




    Rating
    1    600000
    2    600000
    3    600000
    4    600000
    5    600000
    Name: count, dtype: int64




```python
data.value_counts("Sentiment")
```




    Sentiment
    Negative    1200000
    Positive    1200000
    Neutral      600000
    Name: count, dtype: int64




```python
plt.figure(figsize=(5,3))
sns.countplot(x="Sentiment", data=data,  palette=["#f8de7e","#32fa53",'#fa3232'])
plt.title("Rating Count")
plt.show()
```

    C:\Users\srinj\AppData\Local\Temp\ipykernel_11840\2359462227.py:2: FutureWarning: 
    
    Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.
    
      sns.countplot(x="Sentiment", data=data,  palette=["#f8de7e","#32fa53",'#fa3232'])
    


    
![png](output_26_1.png)
    



```python
data["Rating"].value_counts()/len(data)
```




    Rating
    3    0.2
    5    0.2
    4    0.2
    1    0.2
    2    0.2
    Name: count, dtype: float64




```python
data["Sentiment"].value_counts()/len(data)
```




    Sentiment
    Positive    0.4
    Negative    0.4
    Neutral     0.2
    Name: count, dtype: float64




```python
data.isna().sum()
```




    Review       188
    Rating         0
    Sentiment      0
    dtype: int64



We can see that there are no null values in Ratings or Sentiments, so we do not have to drop any rows.
However, there are 188 rows that are empty, so we fill it with an empty string.


```python
data = data.fillna(' ')
data.isna().sum()
```




    Review       0
    Rating       0
    Sentiment    0
    dtype: int64



**Number of characters present in each Review:**

Here I range the number of characters by 500 chars and so on.


```python
text_len = data['Review'].groupby(pd.cut(data['Review'].str.len(), np.arange(0, 20000+500, 500))).count().rename_axis(['Range']).reset_index()
text_len.head()
```

    C:\Users\srinj\AppData\Local\Temp\ipykernel_11840\2468471289.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
      text_len = data['Review'].groupby(pd.cut(data['Review'].str.len(), np.arange(0, 20000+500, 500))).count().rename_axis(['Range']).reset_index()
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Range</th>
      <th>Review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(0, 500]</td>
      <td>1911735</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(500, 1000]</td>
      <td>1071380</td>
    </tr>
    <tr>
      <th>2</th>
      <td>(1000, 1500]</td>
      <td>16885</td>
    </tr>
    <tr>
      <th>3</th>
      <td>(1500, 2000]</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>(2000, 2500]</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
text_len_50 = text_len[text_len['Review'] > 50]
text_len_50
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Range</th>
      <th>Review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(0, 500]</td>
      <td>1911735</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(500, 1000]</td>
      <td>1071380</td>
    </tr>
    <tr>
      <th>2</th>
      <td>(1000, 1500]</td>
      <td>16885</td>
    </tr>
  </tbody>
</table>
</div>




```python
plt.figure(figsize=(12, 4))
g = sns.barplot( x=text_len_50['Range'][0:10], y=text_len_50['Review'][0:10], palette=palette)
g.set_xticklabels(g.get_xticklabels(), rotation=90)
plt.show()
```

    C:\Users\srinj\AppData\Local\Temp\ipykernel_11840\4000903183.py:2: FutureWarning: 
    
    Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.
    
      g = sns.barplot( x=text_len_50['Range'][0:10], y=text_len_50['Review'][0:10], palette=palette)
    C:\Users\srinj\AppData\Local\Temp\ipykernel_11840\4000903183.py:2: UserWarning: 
    The palette list has fewer values (5) than needed (40) and will cycle, which may produce an uninterpretable plot.
      g = sns.barplot( x=text_len_50['Range'][0:10], y=text_len_50['Review'][0:10], palette=palette)
    C:\Users\srinj\AppData\Local\Temp\ipykernel_11840\4000903183.py:3: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
      g.set_xticklabels(g.get_xticklabels(), rotation=90)
    


    
![png](output_35_1.png)
    



```python
plt.figure(figsize=(12, 4))
sns.histplot(data=data, x=data['Review'].str.len(), palette=palette)
plt.show()
```

    C:\Users\srinj\AppData\Local\Temp\ipykernel_11840\1778809724.py:2: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
      sns.histplot(data=data, x=data['Review'].str.len(), palette=palette)
    


    
![png](output_36_1.png)
    


#### **Sampling the data:**
Since there are over 35 million reviews in this dataset, we will only use a portion of this for training our models. We will use Stratified Shuffle Split for this.

Benefits of StratifiedShuffleSplit:

- Maintains class balance: This is crucial for sentiment analysis where you have different classes representing positive, negative, and neutral reviews. Stratified sampling ensures the sampled data reflects the same proportion of each class as your original dataset, preventing biases in your model's training.
- Reduces computational cost: Training on a smaller sample is significantly faster and less resource-intensive compared to using the entire dataset.
- Provides representative data: Stratified sampling ensures the selected data is representative of the entire population, leading to a more robust and generalizable model.


```python
split = StratifiedShuffleSplit(n_splits=1, test_size=0.97)
for train_index, test_index in split.split(data, data["Sentiment"]): 
    strat_data = data.reindex(train_index)
```


```python
strat_data.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Review</th>
      <th>Rating</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2877545</th>
      <td>Insightful and articualate I can't believe the...</td>
      <td>5</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>2477073</th>
      <td>Not terrific, will use my other products inste...</td>
      <td>3</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>118683</th>
      <td>disappointed Despite numerous e-mails to every...</td>
      <td>1</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>761306</th>
      <td>meh not much to say. i found all the waldos ea...</td>
      <td>2</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>320440</th>
      <td>What is going on here... The action was good i...</td>
      <td>2</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>1429635</th>
      <td>Would rather use something else When I bought ...</td>
      <td>3</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>1675641</th>
      <td>Works very well when there's no breeze. I have...</td>
      <td>4</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>1137603</th>
      <td>characters faithful to the show Nice continuat...</td>
      <td>5</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>618513</th>
      <td>Cheaper at Costco I just bought this plasma ca...</td>
      <td>2</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>2347837</th>
      <td>So so I'm not sure what possessed me to order ...</td>
      <td>3</td>
      <td>Neutral</td>
    </tr>
  </tbody>
</table>
</div>



We take a sample dataset of 75000 rows.


```python
strat_data.shape
```




    (90000, 3)




```python
strat_data.value_counts("Sentiment")
```




    Sentiment
    Negative    36000
    Positive    36000
    Neutral     18000
    Name: count, dtype: int64



#### **Cleaning data:**

Cleaning data includes

- Tokenization: Tokenization is the process of converting text into tokens before transforming it into vectors. 
- Stop Words Removal: Stop words are the most commonly occuring words which are not relevant in the context of the data and do not contribute any deeper meaning to the phrase. 
- Normalization: Words which look different due to casing or written another way but are the same in meaning need to be process correctly. Normalisation processes ensure that these words are treated equally. This includes:
    - Casing the characters: Converting character to the same case so the same words are recognised as the same. In this case we converted to lowercase
    - Negation Handling
- Lemmetization: This process finds the base or dictionary form of the word known as the lemma.


```python
nltk.download('wordnet')
```

    [nltk_data] Downloading package wordnet to
    [nltk_data]     C:\Users\srinj\AppData\Roaming\nltk_data...
    [nltk_data]   Package wordnet is already up-to-date!
    




    True




```python
def preprocess_text(text):
    # Make text lowercase and remove links, text in square brackets, punctuation, and words containing numbers
    text = str(text)
    text = text.lower()
    text = re.sub(r'https?://\S+|www\.\S+|\[.*?\]|[^a-zA-Z\s]+|\w*\d\w*', ' ', text)

    # Remove stop words
    stop_words = set(stopwords.words("english"))
    words = text.split()
    filtered_words = [word for word in words if word not in stop_words]
    text = ' '.join(filtered_words).strip()

    # Tokenize
    tokens = nltk.word_tokenize(text)

    # Lemmatize
    lemmatizer = WordNetLemmatizer()
    lem_tokens = [lemmatizer.lemmatize(token) for token in tokens]
    
    return ' '.join(lem_tokens)
```

For example:


```python
import nltk
nltk.download('stopwords')
nltk.download('punkt_tab')
preprocess_text(data["Review"][2])
```

    [nltk_data] Downloading package stopwords to
    [nltk_data]     C:\Users\srinj\AppData\Roaming\nltk_data...
    [nltk_data]   Package stopwords is already up-to-date!
    [nltk_data] Downloading package punkt_tab to
    [nltk_data]     C:\Users\srinj\AppData\Roaming\nltk_data...
    [nltk_data]   Package punkt_tab is already up-to-date!
    




    'best soundtrack ever anything reading lot review saying best game soundtrack figured write review disagree bit opinino yasunori mitsuda ultimate masterpiece music timeless listening year beauty simply refuse fade price tag pretty staggering must say going buy cd much money one feel would worth every penny'




```python
preprocess_text(data["Review"][110])
```




    'fabulous book completely instrumental guiding husband timberframing pursuit read much cover binding fallen broken hold best reference diyer look starting structure'



We do the same for all the reviews in the dataset.


```python
strat_data["Review"] = strat_data["Review"].apply(preprocess_text)
strat_data.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Review</th>
      <th>Rating</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2877545</th>
      <td>insightful articualate believe review pan wond...</td>
      <td>5</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>2477073</th>
      <td>terrific use product instead typically useorth...</td>
      <td>3</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>118683</th>
      <td>disappointed despite numerous e mail everyone ...</td>
      <td>1</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>761306</th>
      <td>meh much say found waldos easily think took fi...</td>
      <td>2</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>320440</th>
      <td>going action good movie everything else crap p...</td>
      <td>2</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>1429635</th>
      <td>would rather use something else bought yogurt ...</td>
      <td>3</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>1675641</th>
      <td>work well breeze using lantern summer live flo...</td>
      <td>4</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>1137603</th>
      <td>character faithful show nice continuation show...</td>
      <td>5</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>618513</th>
      <td>cheaper costco bought plasma car amazon awesom...</td>
      <td>2</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>2347837</th>
      <td>sure possessed order thermometer online instea...</td>
      <td>3</td>
      <td>Neutral</td>
    </tr>
  </tbody>
</table>
</div>



#### **Word Cloud:**


```python
txt = "".join(strat_data["Review"].tolist())
```


```python
len(txt)
```




    24059271




```python
amazon_mask = np.array(Image.open(requests.get('https://pngimg.com/uploads/amazon/amazon_PNG4.png', stream=True).raw))

wc = WordCloud(width = 300, height = 200, random_state=1, background_color='white', colormap='Set2', collocations=False, mask=amazon_mask).generate(txt)
image_colors = ImageColorGenerator(amazon_mask)
wc.recolor(color_func=image_colors)
plt.figure(figsize=(6,6))
plt.axis("off")
plt.tight_layout(pad=0)
plt.imshow(wc, interpolation='bilinear')
plt.title("Amazon Reviews Word Cloud", fontsize = 15)
plt.savefig('wordcloud.png')
plt.show()
```


    
![png](output_54_0.png)
    


TF IDF SCORE


```python
tfidf_vectorizer = TfidfVectorizer(max_features = 5000, ngram_range = (1,3))
```


```python
X_tfidf = tfidf_vectorizer.fit_transform(strat_data['Review'])
X_tfidf
```




    <90000x5000 sparse matrix of type '<class 'numpy.float64'>'
    	with 2804668 stored elements in Compressed Sparse Row format>




```python
X_tfidf.shape
```




    (90000, 5000)




```python
y = strat_data["Sentiment"]
```


```python
y.shape
```




    (90000,)


LOGISTIC REGRESSION 

```python
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, random_state = 42,test_size = 0.20)
```


```python
print(X_train.shape)
print(f"Number of Training Samples: {X_train.shape[0]}")
print(y_train.shape)
print(f"Number of Training Samples: {X_train.shape[0]}")
print(X_test.shape)
print(f"Number of Training Samples: {X_train.shape[0]}")
print(y_test.shape)
print(f"Number of Training Samples: {X_train.shape[0]}")
```

    (72000, 5000)
    Number of Training Samples: 72000
    (72000,)
    Number of Training Samples: 72000
    (18000, 5000)
    Number of Training Samples: 72000
    (18000,)
    Number of Training Samples: 72000
    


```python
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
```

    C:\ProgramData\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(
    




<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;LogisticRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>LogisticRegression()</pre></div> </div></div></div></div>




```python
predictedLogReg = logreg.predict(X_test)
np.mean(predictedLogReg == y_test)
```




    0.7155555555555555




```python
inp_test = input("Enter review: ")
print(inp_test)

inp_test = preprocess_text(inp_test)
print("After preprocessing: ", inp_test)

inp_test = tfidf_vectorizer.transform([inp_test])
logreg.predict(inp_test)
```

    Enter review:  It is a bad product
    

    It is a bad product
    After preprocessing:  bad product
    




    array(['Negative'], dtype=object)




```python

```


This code snippet is for predicting sentiment (e.g., "Positive" or "Negative") of a review using text preprocessing, feature extraction, and a trained logistic regression model:

Input Review: The user provides a review (e.g., "It is a bad product").
Preprocessing: The review is preprocessed (e.g., removing stopwords or punctuation) to simplify the text ("bad product").
Feature Transformation: The preprocessed text is converted into numerical features using a TF-IDF vectorizer (tfidf_vectorizer).
Prediction: A trained logistic regression model (logreg) predicts the sentiment of the review. The output here indicates "Negative" sentiment.



```python

```
